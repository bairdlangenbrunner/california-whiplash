{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Switching to go through each season and save data for EACH ENSEMBLE MEMBER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy\n",
    "import netCDF4\n",
    "import matplotlib.pyplot as mp\n",
    "import matplotlib.ticker\n",
    "\n",
    "mp.rcParams.update({'mathtext.default': 'regular'})\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def geo_idx(dd, dd_array):\n",
    "   \"\"\"\n",
    "     search for nearest decimal degree in an array of decimal degrees and return the index.\n",
    "     np.argmin returns the indices of minium value along an axis.\n",
    "     so subtract dd from all values in dd_array, take absolute value and find index of minium.\n",
    "    \"\"\"\n",
    "   geo_idx = (numpy.abs(dd_array - dd)).argmin()\n",
    "   return geo_idx\n",
    "\n",
    "LA_lat = 34.0522\n",
    "LA_lon = 118.2437 # deg west\n",
    "LA_lon = 180. + (180-LA_lon)\n",
    "\n",
    "Oroville_dam_lat = 39.5380\n",
    "Oroville_dam_lon = 121.4831 # deg west\n",
    "Oroville_dam_lon = 360 - Oroville_dam_lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_subsets = numpy.array((\n",
    "[1920,1940], \\\n",
    "[1940,1960], \\\n",
    "[1960,1980], \\\n",
    "[1980,2000], \\\n",
    "[2000,2020], \\\n",
    "[2020,2040], \\\n",
    "[2040,2060], \\\n",
    "[2060,2080], \\\n",
    "[2080,2100] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_dir = '/ninod/NCAR_LENS/daily/PRECT/hist_and_rcp85/'\n",
    "\n",
    "file_list = numpy.array(( \\\n",
    "'hist_and_rcp85.001.PRECT.18500101-21001231.nc', \\\n",
    "'hist_and_rcp85.002.PRECT.19200101-21001231.nc', \\\n",
    "'hist_and_rcp85.003.PRECT.19200101-21001231.nc', \\\n",
    "'hist_and_rcp85.004.PRECT.19200101-21001231.nc', \\\n",
    "'hist_and_rcp85.005.PRECT.19200101-21001231.nc', \\\n",
    "'hist_and_rcp85.006.PRECT.19200101-21001231.nc', \\\n",
    "'hist_and_rcp85.007.PRECT.19200101-21001231.nc', \\\n",
    "'hist_and_rcp85.008.PRECT.19200101-21001231.nc', \\\n",
    "'hist_and_rcp85.009.PRECT.19200101-21001231.nc', \\\n",
    "'hist_and_rcp85.010.PRECT.19200101-21001231.nc', \\\n",
    "'hist_and_rcp85.011.PRECT.19200101-21001231.nc', \\\n",
    "'hist_and_rcp85.012.PRECT.19200101-21001231.nc', \\\n",
    "'hist_and_rcp85.013.PRECT.19200101-21001231.nc', \\\n",
    "'hist_and_rcp85.014.PRECT.19200101-21001231.nc', \\\n",
    "'hist_and_rcp85.015.PRECT.19200101-21001231.nc', \\\n",
    "'hist_and_rcp85.016.PRECT.19200101-21001231.nc', \\\n",
    "'hist_and_rcp85.017.PRECT.19200101-21001231.nc', \\\n",
    "'hist_and_rcp85.018.PRECT.19200101-21001231.nc', \\\n",
    "'hist_and_rcp85.019.PRECT.19200101-21001231.nc', \\\n",
    "'hist_and_rcp85.020.PRECT.19200101-21001231.nc', \\\n",
    "'hist_and_rcp85.021.PRECT.19200101-21001231.nc', \\\n",
    "'hist_and_rcp85.022.PRECT.19200101-21001231.nc', \\\n",
    "'hist_and_rcp85.023.PRECT.19200101-21001231.nc', \\\n",
    "'hist_and_rcp85.024.PRECT.19200101-21001231.nc', \\\n",
    "'hist_and_rcp85.025.PRECT.19200101-21001231.nc', \\\n",
    "'hist_and_rcp85.026.PRECT.19200101-21001231.nc', \\\n",
    "'hist_and_rcp85.027.PRECT.19200101-21001231.nc', \\\n",
    "'hist_and_rcp85.028.PRECT.19200101-21001231.nc', \\\n",
    "'hist_and_rcp85.029.PRECT.19200101-21001231.nc', \\\n",
    "'hist_and_rcp85.030.PRECT.19200101-21001231.nc', \\\n",
    "'hist_and_rcp85.031.PRECT.19200101-21001231.nc', \\\n",
    "'hist_and_rcp85.032.PRECT.19200101-21001231.nc', \\\n",
    "'hist_and_rcp85.033.PRECT.19200101-21001231.nc', \\\n",
    "'hist_and_rcp85.034.PRECT.19200101-21001231.nc', \\\n",
    "'hist_and_rcp85.035.PRECT.19200101-21001231.nc', \\\n",
    "'hist_and_rcp85.101.PRECT.19200101-21001231.nc', \\\n",
    "'hist_and_rcp85.102.PRECT.19200101-21001231.nc', \\\n",
    "'hist_and_rcp85.103.PRECT.19200101-21001231.nc', \\\n",
    "'hist_and_rcp85.104.PRECT.19200101-21001231.nc', \\\n",
    "'hist_and_rcp85.105.PRECT.19200101-21001231.nc' ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull out proper lat/lon (doing this for one grid point right now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_oct = 31\n",
    "d_nov = 30\n",
    "d_dec = 31\n",
    "d_jan = 31\n",
    "d_feb = 28\n",
    "d_mar = 31\n",
    "days_per_season = d_oct+d_nov+d_dec+d_jan+d_feb+d_mar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 9.3 µs\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "ncfile = netCDF4.Dataset(file_dir + file_list[i])\n",
    "PRECT_lat = ncfile.variables['lat'][:]\n",
    "PRECT_lon = ncfile.variables['lon'][:]\n",
    "PRECT_time_var = ncfile.variables['time']\n",
    "\n",
    "PRECT_time_dates = netCDF4.num2date(PRECT_time_var[:], PRECT_time_var.units, PRECT_time_var.calendar)\n",
    "time_indices_ONDJFM = numpy.array([t.month in [10,11,12,1,2,3] for t in PRECT_time_dates], dtype=bool)\n",
    "PRECT_time_dates_ONDJFM = PRECT_time_dates[time_indices_ONDJFM]\n",
    "\n",
    "LA_lat_idx = geo_idx(LA_lat, PRECT_lat)\n",
    "LA_lon_idx = geo_idx(LA_lon, PRECT_lon)\n",
    "\n",
    "#PRECT_ONDJFM_CA = ncfile.variables['PRECT'][time_indices_ONDJFM,(LA_lat_idx-2):(LA_lat_idx+2), (LA_lon_idx-2):(LA_lon_idx+2)]*86400.*1000\n",
    "PRECT_ONDJFM_CA = ncfile.variables['PRECT'][time_indices_ONDJFM,LA_lat_idx, LA_lon_idx]*86400.*1000\n",
    "\n",
    "% time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# California lat/lon combos\n",
    "ca_latlon_array = numpy.load('ca_latlon_array.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CALCULATE GLOBAL VALUES WHERE THESE EXIST\n",
    "\n",
    "#print(ca_latlon_array[0,0])\n",
    "#print(PRECT_lat[130])\n",
    "global_lat_indices = [numpy.where(numpy.isclose(ca_latlon_array[i,0], PRECT_lat))[0][0] for i in range(ca_latlon_array.shape[0])]\n",
    "#print(global_lat_indices)\n",
    "global_lon_indices = [numpy.where(numpy.isclose(ca_latlon_array[i,1], PRECT_lon))[0][0] for i in range(ca_latlon_array.shape[0])]\n",
    "#print(global_lon_indices)\n",
    "\n",
    "ca_latlon_indices_array = numpy.column_stack((global_lat_indices,global_lon_indices))\n",
    "numpy.save('ca_latlon_indices_array.npy', full_ca_latlon_array)\n",
    "\n",
    "#for i in range(ca_latlon_combos.shape[0]):\n",
    "#    print( numpy.where(ca_latlon_combos[i,0]-PRECT_lat)[0] )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#PRECT_ONDJFM = PRECT_ONDJFM[:, LA_lat_idx, LA_lon_idx]\n",
    "PRECT_ONDJFM_CA = PRECT_ONDJFM[:, (LA_lat_idx-2):(LA_lat_idx+2), (LA_lon_idx-2):(LA_lon_idx+2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLAH BLAH BLAH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "threshold=0.1\n",
    "\n",
    "# for each season, do counts, store them in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "year_start = 1920 #time_subsets[chunk,0]\n",
    "year_end = 2100 #time_subsets[chunk,1]\n",
    "\n",
    "# create season strings\n",
    "years = numpy.arange(year_start, year_end+1, 1).astype(numpy.int)\n",
    "season_strings = numpy.empty(years.size-1, dtype=numpy.str)\n",
    "\n",
    "season_strings = [str(years[i])+'-'+str(years[i+1]) for i in range(years.size-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hist_and_rcp85.001.PRECT.18500101-21001231.nc\n",
      "Saved member_001_latidx_130_lonidx_193_years_1920-2100_threshold_0.1mmday.npy\n"
     ]
    }
   ],
   "source": [
    "n_seasons = year_end-year_start\n",
    "#half_years = numpy.arange(year_start+0.5, year_end, 1.0)\n",
    "\n",
    "for latlon in [0]:#range(ca_latlon_indices_array.shape[0]):\n",
    "    \n",
    "    lat_idx = ca_latlon_indices_array[latlon,0]\n",
    "    lon_idx = ca_latlon_indices_array[latlon,1]\n",
    "    \n",
    "    save_dict = {}\n",
    "\n",
    "    for i in [0]:#range(40):#file_list.size):\n",
    "\n",
    "        print(file_list[i])\n",
    "        ensemble_member = file_list[i].split('.')[1]\n",
    "\n",
    "        ncfile = netCDF4.Dataset(file_dir + file_list[i])\n",
    "        PRECT_lat = ncfile.variables['lat'][:]\n",
    "        PRECT_lon = ncfile.variables['lon'][:]\n",
    "        PRECT_time_var = ncfile.variables['time']\n",
    "\n",
    "        PRECT_time_dates = netCDF4.num2date(PRECT_time_var[:], PRECT_time_var.units, PRECT_time_var.calendar)\n",
    "        time_indices_ONDJFM = numpy.array([(t.month in [10,11,12,1,2,3])&(t.year in range(year_start,year_end+1)) for t in PRECT_time_dates], dtype=bool)\n",
    "        PRECT_time_dates_ONDJFM = PRECT_time_dates[time_indices_ONDJFM]\n",
    "\n",
    "        PRECT_ONDJFM_region = ncfile.variables['PRECT'][time_indices_ONDJFM, lat_idx, lon_idx]*86400.*1000\n",
    "\n",
    "        # get index of first October\n",
    "        # and index of last March\n",
    "        t=0\n",
    "        while t < PRECT_time_dates_ONDJFM.size:\n",
    "            if PRECT_time_dates_ONDJFM[t].month!=10:\n",
    "                t+=1\n",
    "            else:\n",
    "                first_October_index = t\n",
    "                break\n",
    "        t=0\n",
    "        while i < PRECT_time_dates_ONDJFM.size:\n",
    "            if PRECT_time_dates_ONDJFM[::-1][t].month!=3:\n",
    "                t+=1\n",
    "            else:\n",
    "                last_March_index = PRECT_time_dates_ONDJFM.size-t-1\n",
    "                break\n",
    "\n",
    "        PRECT_time_dates_ONDJFM_fullseasons = PRECT_time_dates_ONDJFM[first_October_index:last_March_index+1]\n",
    "        PRECT_ONDJFM_region_fullseasons = PRECT_ONDJFM_region[first_October_index:last_March_index+1]\n",
    "\n",
    "        #years_array = numpy.array(([t.year for t in PRECT_time_dates_ONDJFM_fullseasons]), dtype=numpy.int)\n",
    "\n",
    "        storm_count=0 # per season\n",
    "        storm_length=0 # for each storm\n",
    "        storm_magnitude=0.0 # for each storm\n",
    "\n",
    "        for s in range(n_seasons):\n",
    "            storm_count=0\n",
    "            storm_magnitude_list = []\n",
    "            storm_length_list = []\n",
    "            seas_PRECT = PRECT_ONDJFM_region_fullseasons[s*days_per_season:(s*days_per_season+days_per_season)]\n",
    "            for d in range(days_per_season):\n",
    "                if seas_PRECT[d]>=threshold:\n",
    "                    storm_magnitude+=seas_PRECT[d]\n",
    "                    storm_length+=1 # days\n",
    "                elif (seas_PRECT[d]<threshold)&(storm_magnitude>0.0):\n",
    "                    storm_magnitude_list.append(storm_magnitude)\n",
    "                    storm_length_list.append(storm_length)\n",
    "                    storm_magnitude=0.0\n",
    "                    storm_length=0\n",
    "                    storm_count+=1\n",
    "            seasonal_total = numpy.sum(seas_PRECT[seas_PRECT>threshold])\n",
    "            precipitation_days = numpy.sum(seas_PRECT>threshold)\n",
    "            save_dict[season_strings[s]] = {'storm_count' : storm_count}\n",
    "            save_dict[season_strings[s]]['storm_magnitude_list'] = storm_magnitude_list\n",
    "            save_dict[season_strings[s]]['storm_length_list'] = storm_length_list\n",
    "            save_dict[season_strings[s]]['seasonal_total'] = seasonal_total\n",
    "            save_dict[season_strings[s]]['precipitation_days'] = precipitation_days\n",
    "        \n",
    "    save_file = 'member_'+ensemble_member+'_latidx_'+str(lat_idx)+'_lonidx_'+str(lon_idx)+'_years_'+str(year_start)+'-'+str(year_end)+'_threshold_'+str(threshold)+'mmday.npy'\n",
    "    numpy.save(working_dir + save_file, save_dict)\n",
    "    print('Saved '+save_file)\n",
    "    #'{:03d}'.format(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
