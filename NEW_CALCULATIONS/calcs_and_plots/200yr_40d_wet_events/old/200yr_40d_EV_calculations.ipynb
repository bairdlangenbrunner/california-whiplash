{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy\n",
    "import netCDF4\n",
    "import matplotlib.pyplot as mp\n",
    "import matplotlib.ticker\n",
    "import matplotlib.colors\n",
    "import scipy.stats\n",
    "import pandas\n",
    "import itertools\n",
    "\n",
    "mp.rcParams.update({'mathtext.default': 'regular'})\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "working_dir = '/Users/baird/Dropbox/_analysis/attribution_2017/NEW_CALCULATIONS/npy_files/'\n",
    "#save_dir = '/Users/baird/Dropbox/_analysis/attribution_2017/NEW_CALCULATIONS/calculations/npy_files/'\n",
    "#latlon_indices = numpy.load(working_dir + 'ccal_latlon_indices_array.npy'); region='ccal'\n",
    "#latlon_indices = numpy.load(working_dir + 'ncal_latlon_indices_array.npy'); region='ncal'\n",
    "#latlon_indices = numpy.load(working_dir + 'scal_latlon_indices_array.npy'); region='scal'\n",
    "\n",
    "PRECT_lat = numpy.load('/Users/baird/Dropbox/_analysis/attribution_2017/NEW_CALCULATIONS/npy_files/PRECT_lat.npy')\n",
    "PRECT_lon = numpy.load('/Users/baird/Dropbox/_analysis/attribution_2017/NEW_CALCULATIONS/npy_files/PRECT_lon.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "working_dir = '/Users/baird/google_drive/_data_original/NCAR_LENS/daily/PRECT/calculated_npy_files/'\n",
    "#threshold=0.0\n",
    "threshold=0.1\n",
    "#threshold=0.5\n",
    "#threshold=1.0\n",
    "#threshold=5.0\n",
    "#threshold=10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PRECT_nlat = 26\n",
    "PRECT_nlon = 25\n",
    "\n",
    "latlon_indices = list(itertools.product(range(PRECT_nlat), range(PRECT_nlon)))\n",
    "region = 'whole_domain'\n",
    "window=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open preindustrial control data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year_start_pic = 402 #time_subsets[chunk,0]\n",
    "year_end_pic = 2200 #time_subsets[chunk,1]\n",
    "\n",
    "# create season strings\n",
    "years_pic = numpy.arange(year_start_pic, year_end_pic+1, 1).astype(numpy.int)\n",
    "half_years_pic = numpy.arange(year_start_pic+0.75, year_end_pic, 1)\n",
    "#season_strings_pic = numpy.empty(years.size-1, dtype=numpy.str)\n",
    "\n",
    "season_strings_pic = [str(years_pic[i])+'-'+str(years_pic[i+1]) for i in range(years_pic.size-1)]\n",
    "member_strings_pic = ['{:03d}'.format(i) for i in range(1,36)]\n",
    "\n",
    "n_seasons_pic=year_end_pic-year_start_pic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contruct extreme value distributions for each grid point"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "working_dir = '/Users/baird/Dropbox/_data_original/NCAR_LENS/daily/PRECT/calculated_npy_files/whole_domain/'\n",
    "# for each grid point:\n",
    "# cycle through all times, get extreme 40d sum in each time period, store in array with length(season_strings_pic)\n",
    "# once this is done, calculate the return periods of each of these\n",
    "extreme_values_40d = numpy.zeros(( PRECT_nlat*PRECT_nlon, len(season_strings_pic) ))\n",
    "for latlon_idx in range(len(latlon_indices)):\n",
    "    if latlon_idx%10==0:\n",
    "        print(latlon_idx)\n",
    "    filename = 'member_005_latidx_'+'{:02d}'.format(latlon_indices[latlon_idx][0])+'_lonidx_'+'{:02d}'.format(latlon_indices[latlon_idx][1])+'_years_'+'{:04d}'.format(year_start_pic)+'-'+'{:04d}'.format(year_end_pic)+'_threshold_'+str(threshold)+'mmday_'+region+'.npy'\n",
    "    dict_pic = numpy.load(working_dir + filename).item()\n",
    "    sum_40d_list = [dict_pic[i]['running_40d_sum'] for i in dict_pic.keys()]\n",
    "    for season_idx in range(len(season_strings_pic)):\n",
    "        extreme_values_40d[latlon_idx, season_idx] = numpy.nanmax(sum_40d_list[season_idx])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "extreme_values_40d_df = pandas.DataFrame(extreme_values_40d, columns=[season_strings_pic])\n",
    "extreme_values_40d_df.to_csv('extreme_values_40d_sums_dataframe_pic.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open historical and RCP8.5 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year_start = 1920\n",
    "year_end = 2100\n",
    "\n",
    "year_start_list = [1920,1950,1980,2010,2040,2070]\n",
    "year_end_list = [1950,1980,2010,2040,2070,2100]\n",
    "\n",
    "# create season strings\n",
    "years = numpy.arange(year_start, year_end+1, 1).astype(numpy.int)\n",
    "half_years_hist_rcp = numpy.arange(year_start+0.75, year_end, 1)\n",
    "\n",
    "season_strings_hist_rcp = [str(years[i])+'-'+str(years[i+1]) for i in range(years.size-1)]\n",
    "member_strings_hist_rcp = ['{:03d}'.format(i) for i in range(1,36)]\n",
    "\n",
    "n_seasons_hist_rcp=year_end-year_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemble_members = numpy.hstack((numpy.arange(1,36), numpy.arange(101,106)))\n",
    "ensemble_names = ['{:03d}'.format(i) for i in ensemble_members]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001\n",
      "extreme_values_40d_sums_dataframe_model_001_1920-2100.csv written!\n",
      "002\n",
      "extreme_values_40d_sums_dataframe_model_002_1920-2100.csv written!\n",
      "003\n",
      "extreme_values_40d_sums_dataframe_model_003_1920-2100.csv written!\n",
      "004\n",
      "extreme_values_40d_sums_dataframe_model_004_1920-2100.csv written!\n",
      "005\n",
      "extreme_values_40d_sums_dataframe_model_005_1920-2100.csv written!\n",
      "006\n",
      "extreme_values_40d_sums_dataframe_model_006_1920-2100.csv written!\n",
      "007\n",
      "extreme_values_40d_sums_dataframe_model_007_1920-2100.csv written!\n",
      "008\n",
      "extreme_values_40d_sums_dataframe_model_008_1920-2100.csv written!\n",
      "009\n",
      "extreme_values_40d_sums_dataframe_model_009_1920-2100.csv written!\n",
      "010\n",
      "extreme_values_40d_sums_dataframe_model_010_1920-2100.csv written!\n",
      "011\n",
      "extreme_values_40d_sums_dataframe_model_011_1920-2100.csv written!\n",
      "012\n",
      "extreme_values_40d_sums_dataframe_model_012_1920-2100.csv written!\n",
      "013\n",
      "extreme_values_40d_sums_dataframe_model_013_1920-2100.csv written!\n",
      "014\n",
      "extreme_values_40d_sums_dataframe_model_014_1920-2100.csv written!\n",
      "015\n",
      "extreme_values_40d_sums_dataframe_model_015_1920-2100.csv written!\n",
      "016\n",
      "extreme_values_40d_sums_dataframe_model_016_1920-2100.csv written!\n",
      "017\n",
      "extreme_values_40d_sums_dataframe_model_017_1920-2100.csv written!\n",
      "018\n",
      "extreme_values_40d_sums_dataframe_model_018_1920-2100.csv written!\n",
      "019\n",
      "extreme_values_40d_sums_dataframe_model_019_1920-2100.csv written!\n",
      "020\n",
      "extreme_values_40d_sums_dataframe_model_020_1920-2100.csv written!\n",
      "021\n",
      "extreme_values_40d_sums_dataframe_model_021_1920-2100.csv written!\n",
      "022\n",
      "extreme_values_40d_sums_dataframe_model_022_1920-2100.csv written!\n",
      "023\n",
      "extreme_values_40d_sums_dataframe_model_023_1920-2100.csv written!\n",
      "024\n",
      "extreme_values_40d_sums_dataframe_model_024_1920-2100.csv written!\n",
      "025\n",
      "extreme_values_40d_sums_dataframe_model_025_1920-2100.csv written!\n",
      "026\n",
      "extreme_values_40d_sums_dataframe_model_026_1920-2100.csv written!\n",
      "027\n",
      "extreme_values_40d_sums_dataframe_model_027_1920-2100.csv written!\n",
      "028\n",
      "extreme_values_40d_sums_dataframe_model_028_1920-2100.csv written!\n",
      "029\n",
      "extreme_values_40d_sums_dataframe_model_029_1920-2100.csv written!\n",
      "030\n",
      "extreme_values_40d_sums_dataframe_model_030_1920-2100.csv written!\n",
      "031\n",
      "extreme_values_40d_sums_dataframe_model_031_1920-2100.csv written!\n",
      "032\n",
      "extreme_values_40d_sums_dataframe_model_032_1920-2100.csv written!\n",
      "033\n",
      "extreme_values_40d_sums_dataframe_model_033_1920-2100.csv written!\n",
      "034\n",
      "extreme_values_40d_sums_dataframe_model_034_1920-2100.csv written!\n",
      "035\n",
      "extreme_values_40d_sums_dataframe_model_035_1920-2100.csv written!\n",
      "101\n",
      "extreme_values_40d_sums_dataframe_model_101_1920-2100.csv written!\n",
      "102\n",
      "extreme_values_40d_sums_dataframe_model_102_1920-2100.csv written!\n",
      "103\n",
      "extreme_values_40d_sums_dataframe_model_103_1920-2100.csv written!\n",
      "104\n",
      "extreme_values_40d_sums_dataframe_model_104_1920-2100.csv written!\n",
      "105\n",
      "extreme_values_40d_sums_dataframe_model_105_1920-2100.csv written!\n"
     ]
    }
   ],
   "source": [
    "working_dir = '/Users/baird/Dropbox/_data_original/NCAR_LENS/daily/PRECT/calculated_npy_files/whole_domain/'\n",
    "# for each grid point:\n",
    "# cycle through all times, get extreme 40d sum in each time period, store in array with length(season_strings_pic)\n",
    "# once this is done, calculate the return periods of each of these\n",
    "extreme_values_40d = numpy.zeros(( PRECT_nlat*PRECT_nlon, len(season_strings_hist_rcp) ))\n",
    "\n",
    "for ensemble_idx in range(len(ensemble_members)):\n",
    "    print(ensemble_names[ensemble_idx])\n",
    "    for latlon_idx in range(len(latlon_indices)):\n",
    "        filename = 'member_'+ensemble_names[ensemble_idx]+'_latidx_'+'{:02d}'.format(latlon_indices[latlon_idx][0])+'_lonidx_'+'{:02d}'.format(latlon_indices[latlon_idx][1])+'_years_1920-2100_threshold_'+str(threshold)+'mmday_'+region+'.npy'\n",
    "        #if latlon_idx%10==0:\n",
    "        #    print(latlon_idx)\n",
    "        dict_hist_rcp = numpy.load(working_dir + filename).item()\n",
    "        sum_40d_list = [dict_hist_rcp[i]['running_40d_sum'] for i in dict_hist_rcp.keys()]\n",
    "        for season_idx in range(len(season_strings_hist_rcp)):\n",
    "            extreme_values_40d[latlon_idx, season_idx] = numpy.nanmax(sum_40d_list[season_idx])\n",
    "\n",
    "    extreme_values_40d_df = pandas.DataFrame(extreme_values_40d, columns=[season_strings_hist_rcp])\n",
    "    csv_filename = 'extreme_values_40d_sums_dataframe_model_'+ensemble_names[ensemble_idx]+'_1920-2100.csv'\n",
    "    extreme_values_40d_df.to_csv('csv_files/'+csv_filename)\n",
    "    print(csv_filename, 'written!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
