{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy\n",
    "import netCDF4\n",
    "import matplotlib.pyplot as mp\n",
    "import matplotlib.ticker\n",
    "import matplotlib.colors\n",
    "import scipy.stats\n",
    "import pandas\n",
    "import itertools\n",
    "\n",
    "mp.rcParams.update({'mathtext.default': 'regular'})\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "working_dir = '/Users/baird/Dropbox/_analysis/attribution_2017/NEW_CALCULATIONS/npy_files/'\n",
    "#save_dir = '/Users/baird/Dropbox/_analysis/attribution_2017/NEW_CALCULATIONS/calculations/npy_files/'\n",
    "#latlon_indices = numpy.load(working_dir + 'ccal_latlon_indices_array.npy'); region='ccal'\n",
    "#latlon_indices = numpy.load(working_dir + 'ncal_latlon_indices_array.npy'); region='ncal'\n",
    "#latlon_indices = numpy.load(working_dir + 'scal_latlon_indices_array.npy'); region='scal'\n",
    "\n",
    "PRECT_lat = numpy.load('/Users/baird/Dropbox/_analysis/attribution_2017/NEW_CALCULATIONS/npy_files/PRECT_lat.npy')\n",
    "PRECT_lon = numpy.load('/Users/baird/Dropbox/_analysis/attribution_2017/NEW_CALCULATIONS/npy_files/PRECT_lon.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "working_dir = '/Users/baird/google_drive/_data_original/NCAR_LENS/daily/PRECT/calculated_npy_files/'\n",
    "#threshold=0.0\n",
    "threshold=0.1\n",
    "#threshold=0.5\n",
    "#threshold=1.0\n",
    "#threshold=5.0\n",
    "#threshold=10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PRECT_nlat = 26\n",
    "PRECT_nlon = 25\n",
    "\n",
    "latlon_indices = list(itertools.product(range(PRECT_nlat), range(PRECT_nlon)))\n",
    "region = 'whole_domain'\n",
    "window=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open preindustrial control data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year_start_pic = 402 #time_subsets[chunk,0]\n",
    "year_end_pic = 2200 #time_subsets[chunk,1]\n",
    "\n",
    "# create season strings\n",
    "years_pic = numpy.arange(year_start_pic, year_end_pic+1, 1).astype(numpy.int)\n",
    "half_years_pic = numpy.arange(year_start_pic+0.75, year_end_pic, 1)\n",
    "#season_strings_pic = numpy.empty(years.size-1, dtype=numpy.str)\n",
    "\n",
    "season_strings_pic = [str(years_pic[i])+'-'+str(years_pic[i+1]) for i in range(years_pic.size-1)]\n",
    "member_strings_pic = ['{:03d}'.format(i) for i in range(1,36)]\n",
    "\n",
    "n_seasons_pic=year_end_pic-year_start_pic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull out dry days information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-add44b0bbca8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatlon_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'member_005_latidx_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'{:02d}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatlon_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlatlon_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_lonidx_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'{:02d}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatlon_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlatlon_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_years_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'{:04d}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear_start_pic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'{:04d}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear_end_pic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_threshold_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'mmday_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mregion\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdict_pic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworking_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m#print(dict_pic['402-403'].keys())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdry_days_pic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlatlon_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdict_pic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seasonal_dry_days'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdict_pic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/baird/anaconda/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 406\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    407\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/baird/anaconda/lib/python3.6/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mpickle_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "working_dir = '/Users/baird/Dropbox/_data_original/NCAR_LENS/daily/PRECT/calculated_npy_files/whole_domain/'\n",
    "# for each grid point:\n",
    "# cycle through all times, get extreme 40d sum in each time period, store in array with length(season_strings_pic)\n",
    "# once this is done, calculate the return periods of each of these\n",
    "dry_days_pic = numpy.zeros(( PRECT_nlat*PRECT_nlon, len(season_strings_pic) ))\n",
    "for latlon_idx in range(len(latlon_indices)):\n",
    "    if latlon_idx%10==0:\n",
    "        print(latlon_idx)\n",
    "    filename = 'member_005_latidx_'+'{:02d}'.format(latlon_indices[latlon_idx][0])+'_lonidx_'+'{:02d}'.format(latlon_indices[latlon_idx][1])+'_years_'+'{:04d}'.format(year_start_pic)+'-'+'{:04d}'.format(year_end_pic)+'_threshold_'+str(threshold)+'mmday_'+region+'.npy'\n",
    "    dict_pic = numpy.load(working_dir + filename).item()\n",
    "    #print(dict_pic['402-403'].keys())\n",
    "    dry_days_pic[latlon_idx, :] = [dict_pic[i]['seasonal_dry_days'] for i in dict_pic.keys()]\n",
    "\n",
    "dry_days_pic_df = pandas.DataFrame(dry_days_pic, columns=[season_strings_pic])\n",
    "dry_days_pic_df.to_csv('csv_files/dry_days_pic_dataframe.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open historical and RCP8.5 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year_start = 1920\n",
    "year_end = 2100\n",
    "\n",
    "year_start_list = [1920,1950,1980,2010,2040,2070]\n",
    "year_end_list = [1950,1980,2010,2040,2070,2100]\n",
    "\n",
    "# create season strings\n",
    "years = numpy.arange(year_start, year_end+1, 1).astype(numpy.int)\n",
    "half_years_hist_rcp = numpy.arange(year_start+0.75, year_end, 1)\n",
    "\n",
    "season_strings_hist_rcp = [str(years[i])+'-'+str(years[i+1]) for i in range(years.size-1)]\n",
    "member_strings_hist_rcp = ['{:03d}'.format(i) for i in range(1,36)]\n",
    "\n",
    "n_seasons_hist_rcp=year_end-year_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemble_members = numpy.hstack((numpy.arange(1,36), numpy.arange(101,106)))\n",
    "ensemble_names = ['{:03d}'.format(i) for i in ensemble_members]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001\n",
      "dry_days_hist_rcp_dataframe_model_001_1920-2100.csv written!\n",
      "002\n",
      "dry_days_hist_rcp_dataframe_model_002_1920-2100.csv written!\n",
      "003\n",
      "dry_days_hist_rcp_dataframe_model_003_1920-2100.csv written!\n",
      "004\n",
      "dry_days_hist_rcp_dataframe_model_004_1920-2100.csv written!\n",
      "005\n",
      "dry_days_hist_rcp_dataframe_model_005_1920-2100.csv written!\n",
      "006\n",
      "dry_days_hist_rcp_dataframe_model_006_1920-2100.csv written!\n",
      "007\n",
      "dry_days_hist_rcp_dataframe_model_007_1920-2100.csv written!\n",
      "008\n",
      "dry_days_hist_rcp_dataframe_model_008_1920-2100.csv written!\n",
      "009\n",
      "dry_days_hist_rcp_dataframe_model_009_1920-2100.csv written!\n",
      "010\n",
      "dry_days_hist_rcp_dataframe_model_010_1920-2100.csv written!\n",
      "011\n",
      "dry_days_hist_rcp_dataframe_model_011_1920-2100.csv written!\n",
      "012\n",
      "dry_days_hist_rcp_dataframe_model_012_1920-2100.csv written!\n",
      "013\n",
      "dry_days_hist_rcp_dataframe_model_013_1920-2100.csv written!\n",
      "014\n",
      "dry_days_hist_rcp_dataframe_model_014_1920-2100.csv written!\n",
      "015\n",
      "dry_days_hist_rcp_dataframe_model_015_1920-2100.csv written!\n",
      "016\n",
      "dry_days_hist_rcp_dataframe_model_016_1920-2100.csv written!\n",
      "017\n",
      "dry_days_hist_rcp_dataframe_model_017_1920-2100.csv written!\n",
      "018\n",
      "dry_days_hist_rcp_dataframe_model_018_1920-2100.csv written!\n",
      "019\n",
      "dry_days_hist_rcp_dataframe_model_019_1920-2100.csv written!\n",
      "020\n",
      "dry_days_hist_rcp_dataframe_model_020_1920-2100.csv written!\n",
      "021\n",
      "dry_days_hist_rcp_dataframe_model_021_1920-2100.csv written!\n",
      "022\n",
      "dry_days_hist_rcp_dataframe_model_022_1920-2100.csv written!\n",
      "023\n",
      "dry_days_hist_rcp_dataframe_model_023_1920-2100.csv written!\n",
      "024\n",
      "dry_days_hist_rcp_dataframe_model_024_1920-2100.csv written!\n",
      "025\n",
      "dry_days_hist_rcp_dataframe_model_025_1920-2100.csv written!\n",
      "026\n",
      "dry_days_hist_rcp_dataframe_model_026_1920-2100.csv written!\n",
      "027\n",
      "dry_days_hist_rcp_dataframe_model_027_1920-2100.csv written!\n",
      "028\n",
      "dry_days_hist_rcp_dataframe_model_028_1920-2100.csv written!\n",
      "029\n",
      "dry_days_hist_rcp_dataframe_model_029_1920-2100.csv written!\n",
      "030\n",
      "dry_days_hist_rcp_dataframe_model_030_1920-2100.csv written!\n",
      "031\n",
      "dry_days_hist_rcp_dataframe_model_031_1920-2100.csv written!\n",
      "032\n",
      "dry_days_hist_rcp_dataframe_model_032_1920-2100.csv written!\n",
      "033\n",
      "dry_days_hist_rcp_dataframe_model_033_1920-2100.csv written!\n",
      "034\n",
      "dry_days_hist_rcp_dataframe_model_034_1920-2100.csv written!\n",
      "035\n",
      "dry_days_hist_rcp_dataframe_model_035_1920-2100.csv written!\n",
      "101\n",
      "dry_days_hist_rcp_dataframe_model_101_1920-2100.csv written!\n",
      "102\n",
      "dry_days_hist_rcp_dataframe_model_102_1920-2100.csv written!\n",
      "103\n",
      "dry_days_hist_rcp_dataframe_model_103_1920-2100.csv written!\n",
      "104\n",
      "dry_days_hist_rcp_dataframe_model_104_1920-2100.csv written!\n",
      "105\n",
      "dry_days_hist_rcp_dataframe_model_105_1920-2100.csv written!\n"
     ]
    }
   ],
   "source": [
    "working_dir = '/Users/baird/Dropbox/_data_original/NCAR_LENS/daily/PRECT/calculated_npy_files/whole_domain/'\n",
    "# for each grid point:\n",
    "# cycle through all times, get extreme 40d sum in each time period, store in array with length(season_strings_pic)\n",
    "# once this is done, calculate the return periods of each of these\n",
    "dry_days_hist_rcp = numpy.zeros(( PRECT_nlat*PRECT_nlon, len(season_strings_hist_rcp) ))\n",
    "\n",
    "for ensemble_idx in range(len(ensemble_members)):\n",
    "    print(ensemble_names[ensemble_idx])\n",
    "    for lastlon_idx in range(len(latlon_indices)):\n",
    "        filename = 'member_'+ensemble_names[ensemble_idx]+'_latidx_'+'{:02d}'.format(latlon_indices[latlon_idx][0])+'_lonidx_'+'{:02d}'.format(latlon_indices[latlon_idx][1])+'_years_1920-2100_threshold_'+str(threshold)+'mmday_'+region+'.npy'\n",
    "        #if latlon_idx%10==0:\n",
    "        #    print(latlon_idx)\n",
    "        dict_hist_rcp = numpy.load(working_dir + filename).item()\n",
    "        dry_days_hist_rcp[latlon_idx,:] = [dict_hist_rcp[i]['seasonal_dry_days'] for i in dict_hist_rcp.keys()]\n",
    "\n",
    "    dry_days_hist_rcp_df = pandas.DataFrame(dry_days_hist_rcp, columns=[season_strings_hist_rcp])\n",
    "    csv_filename = 'dry_days_hist_rcp_dataframe_model_'+ensemble_names[ensemble_idx]+'_1920-2100.csv'\n",
    "    dry_days_hist_rcp_df.to_csv('csv_files/'+csv_filename)\n",
    "    print(csv_filename, 'written!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
