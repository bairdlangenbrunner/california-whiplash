{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy\n",
    "import netCDF4\n",
    "import matplotlib.pyplot as mp\n",
    "import matplotlib.ticker\n",
    "import matplotlib.colors\n",
    "import scipy.stats\n",
    "import pandas\n",
    "import itertools\n",
    "\n",
    "mp.rcParams.update({'mathtext.default': 'regular'})\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "working_dir = '/Users/baird/Dropbox/_analysis/attribution_2017/NEW_CALCULATIONS/npy_files/'\n",
    "#save_dir = '/Users/baird/Dropbox/_analysis/attribution_2017/NEW_CALCULATIONS/calculations/npy_files/'\n",
    "#latlon_indices = numpy.load(working_dir + 'ccal_latlon_indices_array.npy'); region='ccal'\n",
    "#latlon_indices = numpy.load(working_dir + 'ncal_latlon_indices_array.npy'); region='ncal'\n",
    "#latlon_indices = numpy.load(working_dir + 'scal_latlon_indices_array.npy'); region='scal'\n",
    "\n",
    "PRECT_lat = numpy.load('/Users/baird/Dropbox/_analysis/attribution_2017/NEW_CALCULATIONS/npy_files/PRECT_lat.npy')\n",
    "PRECT_lon = numpy.load('/Users/baird/Dropbox/_analysis/attribution_2017/NEW_CALCULATIONS/npy_files/PRECT_lon.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "working_dir = '/Users/baird/google_drive/_data_original/NCAR_LENS/daily/PRECT/calculated_npy_files/'\n",
    "#threshold=0.0\n",
    "threshold=0.1\n",
    "#threshold=0.5\n",
    "#threshold=1.0\n",
    "#threshold=5.0\n",
    "#threshold=10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PRECT_nlat = 26\n",
    "PRECT_nlon = 25\n",
    "\n",
    "latlon_indices = list(itertools.product(range(PRECT_nlat), range(PRECT_nlon)))\n",
    "region = 'whole_domain'\n",
    "window=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open preindustrial control data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year_start_pic = 402 #time_subsets[chunk,0]\n",
    "year_end_pic = 2200 #time_subsets[chunk,1]\n",
    "\n",
    "# create season strings\n",
    "years_pic = numpy.arange(year_start_pic, year_end_pic+1, 1).astype(numpy.int)\n",
    "half_years_pic = numpy.arange(year_start_pic+0.75, year_end_pic, 1)\n",
    "#season_strings_pic = numpy.empty(years.size-1, dtype=numpy.str)\n",
    "\n",
    "season_strings_pic = [str(years_pic[i])+'-'+str(years_pic[i+1]) for i in range(years_pic.size-1)]\n",
    "member_strings_pic = ['{:03d}'.format(i) for i in range(1,36)]\n",
    "\n",
    "n_seasons_pic=year_end_pic-year_start_pic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contruct extreme value distributions for each grid point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n"
     ]
    }
   ],
   "source": [
    "working_dir = '/Users/baird/Dropbox/_data_original/NCAR_LENS/daily/PRECT/calculated_npy_files/whole_domain/'\n",
    "# for each grid point:\n",
    "# cycle through all times, get extreme 40d sum in each time period, store in array with length(season_strings_pic)\n",
    "# once this is done, calculate the return periods of each of these\n",
    "extreme_values_seasonal = numpy.zeros(( PRECT_nlat*PRECT_nlon, len(season_strings_pic) ))\n",
    "for latlon_idx in range(len(latlon_indices)):\n",
    "    if latlon_idx%10==0:\n",
    "        print(latlon_idx)\n",
    "    filename = 'member_005_latidx_'+'{:02d}'.format(latlon_indices[latlon_idx][0])+'_lonidx_'+'{:02d}'.format(latlon_indices[latlon_idx][1])+'_years_'+'{:04d}'.format(year_start_pic)+'-'+'{:04d}'.format(year_end_pic)+'_threshold_'+str(threshold)+'mmday_'+region+'.npy'\n",
    "    dict_pic = numpy.load(working_dir + filename).item()\n",
    "    seasonal_events_list = [dict_pic[i]['seasonal_total'] for i in dict_pic.keys()]\n",
    "    for season_idx in range(len(season_strings_pic)):\n",
    "        extreme_values_seasonal[latlon_idx, season_idx] = numpy.nanmax(seasonal_events_list[season_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extreme_values_seasonal_df = pandas.DataFrame(extreme_values_seasonal, columns=[season_strings_pic])\n",
    "extreme_values_seasonal_df.to_csv('csv_files/extreme_values_seasonal_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extreme_values_seasonal_df = pandas.read_csv('csv_files/extreme_values_seasonal_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open historical and RCP8.5 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year_start = 1920\n",
    "year_end = 2100\n",
    "\n",
    "year_start_list = [1920,1950,1980,2010,2040,2070]\n",
    "year_end_list = [1950,1980,2010,2040,2070,2100]\n",
    "\n",
    "# create season strings\n",
    "years = numpy.arange(year_start, year_end+1, 1).astype(numpy.int)\n",
    "half_years_hist_rcp = numpy.arange(year_start+0.75, year_end, 1)\n",
    "\n",
    "season_strings_hist_rcp = [str(years[i])+'-'+str(years[i+1]) for i in range(years.size-1)]\n",
    "member_strings_hist_rcp = ['{:03d}'.format(i) for i in range(1,36)]\n",
    "\n",
    "n_seasons_hist_rcp=year_end-year_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemble_members = numpy.hstack((numpy.arange(1,36), numpy.arange(101,106)))\n",
    "ensemble_names = ['{:03d}'.format(i) for i in ensemble_members]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001\n"
     ]
    }
   ],
   "source": [
    "working_dir = '/Users/baird/Dropbox/_data_original/NCAR_LENS/daily/PRECT/calculated_npy_files/whole_domain/'\n",
    "# for each grid point:\n",
    "# cycle through all times, get extreme 40d sum in each time period, store in array with length(season_strings_pic)\n",
    "# once this is done, calculate the return periods of each of these\n",
    "extreme_values_40d = numpy.zeros(( PRECT_nlat*PRECT_nlon, len(season_strings_hist_rcp) ))\n",
    "\n",
    "for ensemble_idx in range(len(ensemble_members)):\n",
    "    print(ensemble_names[ensemble_idx])\n",
    "    for latlon_idx in range(len(latlon_indices)):\n",
    "        filename = 'member_'+ensemble_names[ensemble_idx]+'_latidx_'+'{:02d}'.format(latlon_indices[latlon_idx][0])+'_lonidx_'+'{:02d}'.format(latlon_indices[latlon_idx][1])+'_years_1920-2100_threshold_'+str(threshold)+'mmday_'+region+'.npy'\n",
    "        #if latlon_idx%10==0:\n",
    "        #    print(latlon_idx)\n",
    "        dict_hist_rcp = numpy.load(working_dir + filename).item()\n",
    "        sum_40d_list = [dict_hist_rcp[i]['running_40d_sum'] for i in dict_hist_rcp.keys()]\n",
    "        for season_idx in range(len(season_strings_hist_rcp)):\n",
    "            extreme_values_40d[latlon_idx, season_idx] = numpy.nanmax(sum_40d_list[season_idx])\n",
    "\n",
    "    extreme_values_40d_df = pandas.DataFrame(extreme_values_40d, columns=[season_strings_hist_rcp])\n",
    "    csv_filename = 'extreme_values_40d_sums_dataframe_model_'+ensemble_names[ensemble_idx]+'_1920-2100.csv'\n",
    "    extreme_values_40d_df.to_csv('csv_files/'+csv_filename)\n",
    "    print(csv_filename, 'written!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
