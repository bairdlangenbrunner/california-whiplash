{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy\n",
    "import netCDF4\n",
    "import matplotlib.pyplot as mp\n",
    "import matplotlib.ticker\n",
    "import matplotlib.colors\n",
    "import scipy.stats\n",
    "import pandas\n",
    "import itertools\n",
    "from mpl_toolkits import basemap\n",
    "import mpl_toolkits.axes_grid1\n",
    "import random\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "degree_sign = u'\\u00B0'\n",
    "mp.rcParams.update({'mathtext.default': 'regular'})\n",
    "mp.rcParams['hatch.color'] = '0.5'\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up lat/lon of locations of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_lat = 34.0522\n",
    "LA_lon = 118.2437 # deg west\n",
    "LA_lon = 180. + (180-LA_lon)\n",
    "\n",
    "Oroville_dam_lat = 39.5380\n",
    "Oroville_dam_lon = 121.4831 # deg west\n",
    "Oroville_dam_lon = 360 - Oroville_dam_lon\n",
    "\n",
    "SF_lat = 37.7749\n",
    "SF_lon = 122.4194\n",
    "SF_lon = 360 - SF_lon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import coastal grid point indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cali_coast_latlon_indices = numpy.load('/Users/baird/Dropbox/_analysis/attribution_2017/NEW_CALCULATIONS/npy_files/coastal_latlon_array_indices_3x.npy')\n",
    "cali_coast_latlon_indices_zip = [i for i in zip(cali_coast_latlon_indices[:,0], cali_coast_latlon_indices[:,1])]\n",
    "\n",
    "cali_coast_latlon_indices_3d = cali_coast_latlon_indices.reshape((11,3,2))\n",
    "#print(cali_coast_latlon_indices_3d[0,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify return period information and percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.0\n"
     ]
    }
   ],
   "source": [
    "#return_period = 200 # in years\n",
    "#events_per_year = 151-40\n",
    "\n",
    "return_period = 25\n",
    "events_per_year = 1\n",
    "\n",
    "return_val_perc = 100*(1-1/(return_period*events_per_year))\n",
    "print(return_val_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "window=30\n",
    "half_window=int(window/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up directories where data are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = '/Users/baird/Dropbox/_analysis/attribution_2017/NEW_CALCULATIONS/npy_files/'\n",
    "#save_dir = '/Users/baird/Dropbox/_analysis/attribution_2017/NEW_CALCULATIONS/calculations/npy_files/'\n",
    "#latlon_indices = numpy.load(working_dir + 'ccal_latlon_indices_array.npy'); region='ccal'\n",
    "#latlon_indices = numpy.load(working_dir + 'ncal_latlon_indices_array.npy'); region='ncal'\n",
    "#latlon_indices = numpy.load(working_dir + 'scal_latlon_indices_array.npy'); region='scal'\n",
    "\n",
    "PRECT_lat = numpy.load('/Users/baird/Dropbox/_analysis/attribution_2017/NEW_CALCULATIONS/npy_files/PRECT_lat.npy')\n",
    "PRECT_lon = numpy.load('/Users/baird/Dropbox/_analysis/attribution_2017/NEW_CALCULATIONS/npy_files/PRECT_lon.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = '/Users/baird/google_drive/_data_original/NCAR_LENS/daily/PRECT/calculated_npy_files/'\n",
    "#threshold=0.0\n",
    "threshold=0.1\n",
    "#threshold=0.5\n",
    "#threshold=1.0\n",
    "#threshold=5.0\n",
    "#threshold=10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import lat/lon information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRECT_nlat = 26\n",
    "PRECT_nlon = 25\n",
    "\n",
    "latlon_indices = list(itertools.product(range(PRECT_nlat), range(PRECT_nlon)))\n",
    "region = 'whole_domain'\n",
    "window=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open PIC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_start_pic = 402 #time_subsets[chunk,0]\n",
    "year_end_pic = 2200 #time_subsets[chunk,1]\n",
    "\n",
    "# create season strings\n",
    "years_pic = numpy.arange(year_start_pic, year_end_pic+1, 1).astype(numpy.int)\n",
    "#half_years_pic = numpy.arange(year_start_pic+0.75, year_end_pic, 1)\n",
    "#season_strings_pic = numpy.empty(years.size-1, dtype=numpy.str)\n",
    "\n",
    "season_strings_pic = [str(years_pic[i])+'-'+str(years_pic[i+1]) for i in range(years_pic.size-1)]\n",
    "member_strings_pic = ['{:03d}'.format(i) for i in range(1,36)]\n",
    "\n",
    "n_seasons_pic=year_end_pic-year_start_pic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save all events as a numpy array, and save return period values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "working_dir = '/Users/baird/Dropbox/_data_original/NCAR_LENS/daily/PRECT/calculated_npy_files/whole_domain/'\n",
    "# for each grid point:\n",
    "# cycle through all times, get extreme seasonal sum in each time period, store in array with length(season_strings_pic)\n",
    "# once this is done, calculate the return periods of each of these\n",
    "return_period_values_pic = numpy.zeros(( PRECT_nlat*PRECT_nlon, 2))\n",
    "all_events_pic = numpy.zeros((len(latlon_indices), n_seasons_pic))\n",
    "\n",
    "for latlon_idx in range(len(latlon_indices)):\n",
    "    if latlon_idx%10==0:\n",
    "        print(latlon_idx)\n",
    "    filename = 'member_005_latidx_'+'{:02d}'.format(latlon_indices[latlon_idx][0])+'_lonidx_'+'{:02d}'.format(latlon_indices[latlon_idx][1])+'_years_'+'{:04d}'.format(year_start_pic)+'-'+'{:04d}'.format(year_end_pic)+'_threshold_'+str(threshold)+'mmday_'+region+'.npy'\n",
    "    dict_pic = numpy.load(working_dir + filename).item()\n",
    "    #print(dict_pic['402-403'].keys())\n",
    "    seasonal_events_list = [dict_pic[i]['seasonal_total'] for i in dict_pic.keys()]\n",
    "    all_events_pic[latlon_idx,:] = seasonal_events_list\n",
    "    return_period_values_pic[latlon_idx,0] = numpy.percentile(seasonal_events_list, return_val_perc)#, interpolation='nearest')\n",
    "    return_period_values_pic[latlon_idx,1] = numpy.sum(seasonal_events_list>return_period_values_pic[latlon_idx,0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "numpy.save('csv_files/all_events_pic.npy', all_events_pic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open all PIC events (which have already been saved as a npy array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_events_pic = numpy.load('csv_files/all_events_pic.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open return period calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_period_values_pic_df = pandas.read_csv('csv_files/return_period_values_pic_df.csv')\n",
    "return_period_values_pic = return_period_values_pic_df.values[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open historical, RCP and place all data into a 3d array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_members = numpy.hstack((numpy.arange(1,36), numpy.arange(101,106)))\n",
    "ensemble_names = ['{:03d}'.format(i) for i in ensemble_members]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_start = 1920\n",
    "year_end = 2100\n",
    "\n",
    "year_start_list = numpy.arange(1920,2100)\n",
    "year_end_list = numpy.arange(1921,2101)\n",
    "year_middle_list = year_start_list+1\n",
    "\n",
    "# create season strings\n",
    "years = numpy.arange(year_start, year_end+1, 1).astype(numpy.int)\n",
    "half_years_hist_rcp = numpy.arange(year_start+0.75, year_end, 1)\n",
    "season_strings_hist_rcp = [str(i)+'-'+str(i+1) for i in range(year_start,year_end)]\n",
    "\n",
    "thirty_yr_strings_hist_rcp = [str(year_start_list[i])+'-'+str(year_end_list[i]) for i in range(year_start_list.size)]\n",
    "member_strings_hist_rcp = ['{:03d}'.format(i) for i in range(1,36)]\n",
    "\n",
    "n_seasons_hist_rcp=year_end-year_start"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# loop through every grid point and attach ALL ensemble members information\n",
    "all_events_total = []\n",
    "total_events_each_latlon = []\n",
    "all_events_hist_rcp = numpy.zeros(( 650, 40, n_seasons_hist_rcp ))\n",
    "\n",
    "for latlon_idx in range(len(latlon_indices)):\n",
    "    if latlon_idx%10==0:\n",
    "        print(latlon_idx)\n",
    "    total_events_each_latlon = []\n",
    "    for ensemble_idx in range(len(ensemble_members)):\n",
    "        filename = 'member_'+ensemble_names[ensemble_idx]+'_latidx_'+'{:02d}'.format(latlon_indices[latlon_idx][0])+'_lonidx_'+'{:02d}'.format(latlon_indices[latlon_idx][1])+'_years_1920-2100_threshold_'+str(threshold)+'mmday_'+region+'.npy'\n",
    "        dict_hist_rcp = numpy.load(working_dir+filename).item()\n",
    "        total_events_each_latlon.append( [dict_hist_rcp[i]['seasonal_total'] for i in season_strings_hist_rcp] )\n",
    "        all_events_hist_rcp[latlon_idx,ensemble_idx,:] = total_events_each_latlon[-1]\n",
    "    #all_events_total.append(total_events_each_latlon)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "numpy.save('all_events_hist_rcp_3d.npy', all_events_hist_rcp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open all data already saved in npy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(650, 40, 180)\n"
     ]
    }
   ],
   "source": [
    "all_events_hist_rcp_3d = numpy.load('csv_files/all_events_hist_rcp_3d.npy')\n",
    "print(all_events_hist_rcp_3d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate all return periods for all time (1 year at a time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n"
     ]
    }
   ],
   "source": [
    "print(n_seasons_hist_rcp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlat_unique = numpy.unique(cali_coast_latlon_indices[:,0]).size\n",
    "return_period_values_hist_rcp = numpy.zeros((len(latlon_indices), n_seasons_hist_rcp, 3))\n",
    "#print(latitude_time_values.shape)\n",
    "\n",
    "window=1\n",
    "\n",
    "for yr_idx in range(n_seasons_hist_rcp):\n",
    "    season_strings_hist_rcp = [str(i)+'-'+str(i+1) for i in range(year_start,year_end)]\n",
    "    #return_period_values_hist_rcp = numpy.zeros(( PRECT_nlat*PRECT_nlon, 3 ))\n",
    "    \n",
    "    for latlon_idx in range(len(latlon_indices)):\n",
    "\n",
    "        # collect seasonal events for the specific 30 year chunk\n",
    "        seasonal_events = all_events_hist_rcp_3d[latlon_idx,:,yr_idx:yr_idx+window].reshape((-1))\n",
    "\n",
    "        return_period_values_hist_rcp[latlon_idx,yr_idx,0] = numpy.percentile(seasonal_events, return_val_perc)\n",
    "        return_period_values_hist_rcp[latlon_idx,yr_idx,1] = numpy.sum(seasonal_events>return_period_values_hist_rcp[latlon_idx,yr_idx,0])\n",
    "        return_period_values_hist_rcp[latlon_idx,yr_idx,2] = numpy.sum(seasonal_events>return_period_values_pic[latlon_idx,0])\n",
    "    #return_period_values_hist_rcp_df = pandas.DataFrame(return_period_values_hist_rcp, columns=['Perc value hist eoc','Num hist eoc exceedances','Num PIC exceedances'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using scipy library to calculate AD k-sample test"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(n_seasons_hist_rcp)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# for each 30 year chunk, and for each latlon, compare each gridpoint's distribution of \n",
    "sig_test_values = numpy.zeros((11,n_seasons_hist_rcp))\n",
    "\n",
    "all_events_hist_rcp_cali_coast = all_events_hist_rcp_3d.reshape((PRECT_nlat, PRECT_nlon, 40, n_seasons_hist_rcp))[ cali_coast_latlon_indices[:,0], cali_coast_latlon_indices[:,1], :,:]\n",
    "#print(all_events_hist_rcp_cali_coast.shape)\n",
    "all_events_hist_rcp_cali_coast = all_events_hist_rcp_cali_coast.reshape((11,3,40,n_seasons_hist_rcp))\n",
    "#print(all_events_hist_rcp_cali_coast.shape)\n",
    "\n",
    "all_events_pic_cali_coast_2d = all_events_pic.reshape((PRECT_nlat, PRECT_nlon, -1))[ cali_coast_latlon_indices[:,0], cali_coast_latlon_indices[:,1], :]\n",
    "print(all_events_pic_cali_coast_2d.shape)\n",
    "all_events_pic_cali_coast_3d = all_events_pic_cali_coast_2d.reshape((11,3,-1))\n",
    "print(all_events_pic_cali_coast_3d.shape)\n",
    "\n",
    "#all_events_pic\n",
    "sig_test_crit_vals = []\n",
    "for yr_idx in range(n_seasons_hist_rcp):\n",
    "    latlon_crit_vals = []\n",
    "    for lat_idx in range(all_events_hist_rcp_cali_coast.shape[0]):\n",
    "        hist_rcp_data = all_events_hist_rcp_cali_coast[lat_idx,:,:,yr_idx:yr_idx+1].flatten()\n",
    "        #sig_test_values[lat_idx,yr_idx] = scipy.stats.ttest_ind(all_events_pic_cali_coast_3d[lat_idx,:,:].flatten(), hist_rcp_data, equal_var=False)[1]\n",
    "        #sig_test_values[lat_idx,yr_idx] = scipy.stats.ttest_ind(all_events_pic_cali_coast_3d[lat_idx,:,:].flatten(), hist_rcp_data)[1]\n",
    "        #sig_test_values[lat_idx,yr_idx] = scipy.stats.ks_2samp(all_events_pic_cali_coast_3d[lat_idx,:,:].flatten(), hist_rcp_data)[1]\n",
    "        crit_vals, sig_test_values[lat_idx,yr_idx] = scipy.stats.anderson_ksamp([all_events_pic_cali_coast_3d[lat_idx,:,:].flatten(), hist_rcp_data], midrank=False)[1:3]\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(sig_test_values)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cf=mp.contourf(sig_test_values, levels=numpy.arange(0,1.1,0.1))\n",
    "mp.colorbar(cf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using R library to calculate AD k-sample test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/baird/anaconda/envs/pyR/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:145: RRuntimeWarning: Error in loadNamespace(name) : there is no package called ‘kSamples’\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/Users/baird/anaconda/envs/pyR/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:145: RRuntimeWarning: In addition: \n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/Users/baird/anaconda/envs/pyR/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:145: RRuntimeWarning: There were 22 warnings (use warnings() to see them)\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/Users/baird/anaconda/envs/pyR/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:145: RRuntimeWarning: \n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n"
     ]
    },
    {
     "ename": "RRuntimeError",
     "evalue": "Error in loadNamespace(name) : there is no package called ‘kSamples’\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRRuntimeError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-10733d2e98f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mrpy2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrobjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpackages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinstalled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'kSamples'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#utils.install_packages('kSamples')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mkSamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrpy2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrobjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpackages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimportr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'kSamples'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m#ad_test = rpy2.robjects.r['ad.test']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/pyR/lib/python3.5/site-packages/rpy2/robjects/packages.py\u001b[0m in \u001b[0;36mimportr\u001b[0;34m(name, lib_loc, robject_translations, signature_translation, suppress_messages, on_conflict, symbol_r2python, symbol_check_after, data)\u001b[0m\n\u001b[1;32m    451\u001b[0m     if _package_has_namespace(rname, \n\u001b[1;32m    452\u001b[0m                               _system_file(package = rname)):\n\u001b[0;32m--> 453\u001b[0;31m         \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m         \u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_namespace_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0mexported_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_namespace_exports\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRRuntimeError\u001b[0m: Error in loadNamespace(name) : there is no package called ‘kSamples’\n"
     ]
    }
   ],
   "source": [
    "import rpy2\n",
    "import rpy2.robjects.packages\n",
    "\n",
    "#rpy2.robjects.packages.isinstalled('utils')\n",
    "utils = rpy2.robjects.packages.importr('utils')\n",
    "utils.chooseCRANmirror(ind=1)\n",
    "#utils.getCRANmirrors()\n",
    "\n",
    "rpy2.robjects.packages.isinstalled('kSamples')\n",
    "#utils.install_packages('kSamples')\n",
    "kSamples = rpy2.robjects.packages.importr('kSamples')\n",
    "#ad_test = rpy2.robjects.r['ad.test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_seasons_hist_rcp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_test_values = numpy.zeros((11,n_seasons_hist_rcp))\n",
    "\n",
    "all_events_hist_rcp_cali_coast = all_events_hist_rcp_3d.reshape((PRECT_nlat, PRECT_nlon, 40, n_seasons_hist_rcp))[ cali_coast_latlon_indices[:,0], cali_coast_latlon_indices[:,1], :,:]\n",
    "#print(all_events_hist_rcp_cali_coast.shape)\n",
    "all_events_hist_rcp_cali_coast = all_events_hist_rcp_cali_coast.reshape((11,3,40,n_seasons_hist_rcp))\n",
    "#print(all_events_hist_rcp_cali_coast.shape)\n",
    "\n",
    "all_events_pic_cali_coast_2d = all_events_pic.reshape((PRECT_nlat, PRECT_nlon, -1))[ cali_coast_latlon_indices[:,0], cali_coast_latlon_indices[:,1], :]\n",
    "#print(all_events_pic_cali_coast_2d.shape)\n",
    "all_events_pic_cali_coast_3d = all_events_pic_cali_coast_2d.reshape((11,3,-1))\n",
    "#print(all_events_pic_cali_coast_3d.shape)\n",
    "\n",
    "#all_events_pic\n",
    "sig_test_crit_vals = []\n",
    "for yr_idx in range(n_seasons_hist_rcp):\n",
    "    print(yr_idx)\n",
    "    latlon_crit_vals = []\n",
    "    for lat_idx in range(all_events_hist_rcp_cali_coast.shape[0]):\n",
    "        \n",
    "        hist_rcp_data = all_events_hist_rcp_cali_coast[lat_idx,:,:,yr_idx].flatten()\n",
    "        pic_data = all_events_pic_cali_coast_3d[lat_idx,:,:].flatten()\n",
    "        \n",
    "        #pic_median = numpy.nanpercentile(pic_data, 50)\n",
    "        #hist_rcp_data = hist_rcp_data[hist_rcp_data>=pic_median]\n",
    "        #pic_data = pic_data[pic_data>=pic_median]\n",
    "        \n",
    "        #hist_rcp_data = all_events_hist_rcp_cali_coast[lat_idx,:,:,yr_idx:yr_idx+30].flatten()\n",
    "        d1 = rpy2.robjects.FloatVector(hist_rcp_data)\n",
    "        d2 = rpy2.robjects.FloatVector(pic_data)\n",
    "        sig_test_values[lat_idx,yr_idx] = ad_test(d1,d2)[6][4]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "numpy.save('csv_files/sig_test_values_r_median_no_smoothing.npy', sig_test_values)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "sig_test_values = numpy.load('csv_files/sig_test_values_r_median_no_smoothing.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signif. test with moving window smoothing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "window = 30\n",
    "half_window = int(window/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sig_test_values = numpy.zeros((11,n_seasons_hist_rcp))\n",
    "\n",
    "all_events_hist_rcp_cali_coast = all_events_hist_rcp_3d.reshape((PRECT_nlat, PRECT_nlon, 40, n_seasons_hist_rcp))[ cali_coast_latlon_indices[:,0], cali_coast_latlon_indices[:,1], :,:]\n",
    "#print(all_events_hist_rcp_cali_coast.shape)\n",
    "all_events_hist_rcp_cali_coast = all_events_hist_rcp_cali_coast.reshape((11,3,40,n_seasons_hist_rcp))\n",
    "#print(all_events_hist_rcp_cali_coast.shape)\n",
    "\n",
    "all_events_pic_cali_coast_2d = all_events_pic.reshape((PRECT_nlat, PRECT_nlon, -1))[ cali_coast_latlon_indices[:,0], cali_coast_latlon_indices[:,1], :]\n",
    "#print(all_events_pic_cali_coast_2d.shape)\n",
    "all_events_pic_cali_coast_3d = all_events_pic_cali_coast_2d.reshape((11,3,-1))\n",
    "#print(all_events_pic_cali_coast_3d.shape)\n",
    "\n",
    "#all_events_pic\n",
    "sig_test_crit_vals = []\n",
    "for yr_idx in range(half_window, n_seasons_hist_rcp-half_window):\n",
    "    print(yr_idx)\n",
    "    latlon_crit_vals = []\n",
    "    for lat_idx in range(all_events_hist_rcp_cali_coast.shape[0]):\n",
    "        \n",
    "        hist_rcp_data = all_events_hist_rcp_cali_coast[lat_idx,:,:,(yr_idx-half_window):(yr_idx+half_window)].flatten()\n",
    "        pic_data = all_events_pic_cali_coast_3d[lat_idx,:,:].flatten()\n",
    "        \n",
    "        #pic_median = numpy.nanpercentile(pic_data, 50)\n",
    "        #hist_rcp_data = hist_rcp_data[hist_rcp_data>=pic_median]\n",
    "        #pic_data = pic_data[pic_data>=pic_median]\n",
    "        \n",
    "        #hist_rcp_data = all_events_hist_rcp_cali_coast[lat_idx,:,:,yr_idx:yr_idx+30].flatten()\n",
    "        d1 = rpy2.robjects.FloatVector(hist_rcp_data)\n",
    "        d2 = rpy2.robjects.FloatVector(pic_data)\n",
    "        sig_test_values[lat_idx,yr_idx] = ad_test(d1,d2)[6][4]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "numpy.save('csv_files/sig_test_values_window_'+str(window)+'yrs.npy', sig_test_values)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print('csv_files/sig_test_values_window_'+str(window)+'yrs.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# repeat the steps above to generate all possible window smoothing options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_test_values_10 = numpy.load('csv_files/sig_test_values_window_10yrs.npy'); sig_test = '10yr'\n",
    "sig_test_values_10[sig_test_values_10==0.0]=numpy.nan\n",
    "\n",
    "sig_test_values_5 = numpy.load('csv_files/sig_test_values_window_6yrs.npy'); sig_test = '5yr'\n",
    "sig_test_values_5[sig_test_values_5==0.0]=numpy.nan\n",
    "\n",
    "sig_test_values_30 = numpy.load('csv_files/sig_test_values_window_30yrs.npy'); sig_test = '30yr'\n",
    "sig_test_values_30[sig_test_values_30==0.0]=numpy.nan\n",
    "\n",
    "sig_test_values_1 = numpy.load('csv_files/sig_test_values_no_smoothing.npy'); sig_test = '1yr'\n",
    "sig_test_values_1[sig_test_values_1==0.0]=numpy.nan\n",
    "\n",
    "sig_test_values = numpy.load('csv_files/sig_test_values_no_smoothing.npy'); sig_test = '1yr'\n",
    "sig_test_values[sig_test_values==0.0]=numpy.nan\n",
    "\n",
    "sig_vals_list = [sig_test_values_1, sig_test_values_5, sig_test_values_10, sig_test_values_30]\n",
    "sig_vals_labels = ['1yr','5yr','10yr','30yr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cf=mp.contourf(sig_test_values, levels=[0,0.1,0.5,1], extend='max')\n",
    "cf=mp.contourf(sig_test_values)#, extend='max')\n",
    "mp.colorbar(cf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALSO calculating average return period values for 3 lon/lat grid points approaching California coast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate ratio of frequencies of exceedance\n",
    "pic_counts = return_period_values_pic[:,1]\n",
    "hist_rcp_counts = return_period_values_hist_rcp[:,:,2]\n",
    "\n",
    "#return_values_pic_2d = return_period_values_pic[:,0].reshape(PRECT_nlat, PRECT_nlon)\n",
    "#return_values_hist_rcp_2d = return_period_values_hist_rcp[:,0].reshape(PRECT_nlat, PRECT_nlon)\n",
    "\n",
    "print(pic_counts.shape, hist_rcp_counts.shape)\n",
    "count_ratio = ((hist_rcp_counts/(40)).T/(pic_counts/1798)).T\n",
    "count_ratio_2d = count_ratio.reshape((PRECT_nlat, PRECT_nlon, -1))\n",
    "count_ratio_2d_cali = numpy.mean( count_ratio_2d[cali_coast_latlon_indices[:,0],cali_coast_latlon_indices[:,1],:].reshape((11,3,-1)) , axis=1)\n",
    "\n",
    "return_period_values_hist_rcp_4d = return_period_values_hist_rcp.reshape((PRECT_nlat,PRECT_nlon,-1,3))\n",
    "return_period_values_hist_rcp_cali_coast = return_period_values_hist_rcp_4d[cali_coast_latlon_indices[:,0], \\\n",
    "                                                                           cali_coast_latlon_indices[:,1], \\\n",
    "                                                                           :,:]\n",
    "\n",
    "return_period_values_hist_rcp_cali_coast = numpy.mean(return_period_values_hist_rcp_cali_coast.reshape((11,3,-1,3)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hist_rcp_counts_cali_coast = numpy.mean(hist_rcp_counts[cali_coast_latlon_indices[:,0],cali_coast_latlon_indices[:,1],:])\n",
    "hist_rcp_counts_2d = numpy.reshape(hist_rcp_counts, (PRECT_nlat, PRECT_nlon, -1))\n",
    "hist_rcp_counts_2d_cali_coast = hist_rcp_counts_2d[cali_coast_latlon_indices[:,0],cali_coast_latlon_indices[:,1],:]\n",
    "hist_rcp_counts_2d_cali_coast = numpy.mean( hist_rcp_counts_2d_cali_coast.reshape((11,3,-2)), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do same calculation for PIC runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(return_period_values_pic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_period_values_pic_4d = return_period_values_pic[:,0].reshape((PRECT_nlat,PRECT_nlon))\n",
    "return_period_values_pic_cali_coast = return_period_values_pic_4d[cali_coast_latlon_indices[:,0], \\\n",
    "                                                                           cali_coast_latlon_indices[:,1]]\n",
    "\n",
    "return_period_values_pic_cali_coast = numpy.mean(return_period_values_pic_cali_coast.reshape((11,3,-1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(return_period_values_pic_cali_coast.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now plot for hist+RCP8.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize=12\n",
    "\n",
    "fig = mp.figure(figsize=(8,3))\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax_cf = ax.contourf(half_years_hist_rcp, PRECT_lat[numpy.unique(cali_coast_latlon_indices[:,0])], return_period_values_hist_rcp_cali_coast[:,:,0], cmap='gist_earth_r')\n",
    "#ax.set_xticks()\n",
    "\n",
    "la_color = 'saddlebrown'\n",
    "sf_color = 'darkgreen'\n",
    "od_color = '#007070' # '#008080' is teal\n",
    "\n",
    "#ax.axhline(LA_lat, c='firebrick', zorder=1)\n",
    "ax.axhline(LA_lat, c=la_color, zorder=1)\n",
    "ax.axhline(SF_lat, c=sf_color, zorder=1)\n",
    "ax.axhline(Oroville_dam_lat, c=od_color, zorder=1)\n",
    "\n",
    "ax.text(s='LA', x=2105, y=LA_lat, color=la_color, ha='center', va='center', fontsize=fontsize, weight='bold')\n",
    "ax.text(s='SF', x=2105, y=SF_lat, color=sf_color, ha='center', va='center', fontsize=fontsize, weight='bold')\n",
    "ax.text(s='OD', x=2105, y=Oroville_dam_lat, color=od_color, ha='center', va='center', fontsize=fontsize, weight='bold')\n",
    "\n",
    "ax.set_xlim(1920,2100)\n",
    "ax.set_xticks(numpy.arange(1920,2101,30))\n",
    "ax.set_yticks(numpy.arange(34,43,2))\n",
    "\n",
    "ax.tick_params(labelsize=fontsize)\n",
    "\n",
    "ax.set_ylabel('latitude ('+degree_sign+'N)', fontsize=fontsize)\n",
    "ax.set_xlabel('year', fontsize=fontsize)\n",
    "\n",
    "divider = mpl_toolkits.axes_grid1.make_axes_locatable(ax)\n",
    "cbar_ax = divider.append_axes('right', size='2.5%', pad=0.4) #fig.add_axes([0.0, -0.02, 1.0, 0.03])\n",
    "cbar = fig.colorbar(ax_cf, cax=cbar_ax, orientation='vertical')\n",
    "cbar.set_label('mm', fontsize=fontsize)\n",
    "cbar.ax.tick_params(labelsize=fontsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating changes in frequency of occurrence\n",
    "\n",
    "# ALSO calculating return period values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate ratio of frequencies of exceedance\n",
    "pic_counts = return_period_values_pic[:,1]\n",
    "hist_rcp_counts = return_period_values_hist_rcp[:,:,2]\n",
    "\n",
    "#return_values_pic_2d = return_period_values_pic[:,0].reshape(PRECT_nlat, PRECT_nlon)\n",
    "#return_values_hist_rcp_2d = return_period_values_hist_rcp[:,0].reshape(PRECT_nlat, PRECT_nlon)\n",
    "\n",
    "print(pic_counts.shape, hist_rcp_counts.shape)\n",
    "count_ratio = ((hist_rcp_counts/(40)).T/(pic_counts/1798)).T\n",
    "count_ratio_2d = count_ratio.reshape((PRECT_nlat, PRECT_nlon, -1))\n",
    "count_ratio_2d_cali = numpy.mean( count_ratio_2d[cali_coast_latlon_indices[:,0],cali_coast_latlon_indices[:,1],:].reshape((11,3,-1)) , axis=1)\n",
    "\n",
    "hist_rcp_counts_2d = numpy.reshape(hist_rcp_counts, (PRECT_nlat,PRECT_nlon,-1))\n",
    "pic_counts_2d = numpy.reshape(pic_counts, (PRECT_nlat,PRECT_nlon))\n",
    "\n",
    "return_period_values_pic_2d = numpy.reshape(return_period_values_pic, (PRECT_nlat, PRECT_nlon,-1))\n",
    "\n",
    "pic_counts_2d_cali_coast = numpy.mean(pic_counts_2d[cali_coast_latlon_indices[:,0],cali_coast_latlon_indices[:,1]].reshape((11,3)), axis=1)                                        \n",
    "                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pic_counts_2d_cali_coast)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cf = mp.contourf(pic_counts_2d, levels=[70.5,71.5,72.5,73.5])\n",
    "mp.colorbar(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MidpointNormalize(matplotlib.colors.Normalize):\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        self.midpoint = midpoint\n",
    "        matplotlib.colors.Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        # I'm ignoring masked values and all kinds of edge cases to make a\n",
    "        # simple example...\n",
    "        x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
    "        return numpy.ma.masked_array(numpy.interp(value, x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make color map\n",
    "minval=0.0 # \n",
    "maxval=0.85 #\n",
    "n=256\n",
    "full_cmap = mp.get_cmap('RdBu')\n",
    "cmap_partial = matplotlib.colors.LinearSegmentedColormap.from_list('trunc({n},{a:.2f},{b:.2f})'.format(n=full_cmap.name, a=minval, b=maxval), full_cmap(numpy.linspace(minval, maxval, n)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# calculate where significant for advanced test\n",
    "count_ratio_2d_cali_bool = numpy.zeros((nlat_cc,150))\n",
    "for i in range(nlat_cc):\n",
    "    for j in range(150):\n",
    "        count_ratio_2d_cali_bool[i,j] = (count_ratio_2d_cali[i,j]<=bootstrap_siglevels_lo[i,j]) or (count_ratio_2d_cali[i,j]>=bootstrap_siglevels_hi[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize=12\n",
    "\n",
    "\n",
    "fig = mp.figure(figsize=(8,3))\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "contour_levels = numpy.arange(0,5.1,0.2)\n",
    "\n",
    "ax_cf = ax.contourf(half_years_hist_rcp, \\\n",
    "                    PRECT_lat[numpy.unique(cali_coast_latlon_indices[:,0])], \\\n",
    "                    count_ratio_2d_cali, \\\n",
    "                    norm=MidpointNormalize(midpoint=1.0), \\\n",
    "                    cmap='RdBu', \\\n",
    "                    levels=contour_levels, \\\n",
    "                    extend='max')\n",
    "\n",
    "ax_sig = ax.contourf(year_middle_list, \\\n",
    "                    PRECT_lat[numpy.unique(cali_coast_latlon_indices[:,0])], \\\n",
    "                    sig_test_values, \\\n",
    "                    #count_ratio_2d_cali_bool, \\\n",
    "                    colors='None', \\\n",
    "                    levels=[0.0,0.01,1.0], \\\n",
    "                    #levels=[0.05,1.5], \\\n",
    "                    hatches=['///',None], \\\n",
    "                    extend='lower', \\\n",
    "                    edgecolors='red', \\\n",
    "                    zorder=2)\n",
    "\n",
    "# ax_c = ax.contour(half_years_hist_rcp, \\\n",
    "#                     PRECT_lat[numpy.unique(cali_coast_latlon_indices[:,0])], \\\n",
    "#                     count_ratio_2d_cali, \\\n",
    "#                     norm=MidpointNormalize(midpoint=1.0), \\\n",
    "#                     levels=[0,0.5,1,1.5,2,3,4,5], \\\n",
    "#                     colors='0.5', \\\n",
    "#                     linestyles=['--']*2+[':']+['-']*5, \\\n",
    "#                     linewidths=[1]*2+[2]+[1]*5, \\\n",
    "#                     zorder=3)\n",
    "\n",
    "# new_levels = []\n",
    "# for i in ax_c.levels:\n",
    "#     if i in [0.5,1.5]:\n",
    "#         new_levels.append('{:.1f}'.format(i))\n",
    "#     else:\n",
    "#         new_levels.append('{:.0f}'.format(i))\n",
    "# ax_c.levels = new_levels\n",
    "# mp.clabel(ax_c, fontsize=fontsize, colors='0.25')\n",
    "\n",
    "la_color = 'saddlebrown'\n",
    "sf_color = 'darkgreen'\n",
    "od_color = '#007070' # '#008080' is teal\n",
    "\n",
    "#ax.axhline(LA_lat, c='firebrick', zorder=1)\n",
    "ax.axhline(LA_lat, c=la_color, zorder=2)\n",
    "ax.axhline(SF_lat, c=sf_color, zorder=2)\n",
    "ax.axhline(Oroville_dam_lat, c=od_color, zorder=2)\n",
    "\n",
    "ax.text(s='LA', x=2105, y=LA_lat, color=la_color, ha='center', va='center', fontsize=fontsize, weight='bold')\n",
    "ax.text(s='SF', x=2105, y=SF_lat, color=sf_color, ha='center', va='center', fontsize=fontsize, weight='bold')\n",
    "ax.text(s='OD', x=2105, y=Oroville_dam_lat, color=od_color, ha='center', va='center', fontsize=fontsize, weight='bold')\n",
    "\n",
    "ax.set_xlim(1920,2100)\n",
    "ax.set_xticks(numpy.arange(1920,2101,30))\n",
    "ax.set_yticks(numpy.arange(34,43,2))\n",
    "\n",
    "ax.tick_params(labelsize=fontsize)\n",
    "\n",
    "ax.set_ylabel('latitude ('+degree_sign+'N)', fontsize=fontsize)\n",
    "ax.set_xlabel('year', fontsize=fontsize)\n",
    "\n",
    "divider = mpl_toolkits.axes_grid1.make_axes_locatable(ax)\n",
    "cbar_ax = divider.append_axes('right', size='2.5%', pad=0.4)\n",
    "cbar = fig.colorbar(ax_cf, cax=cbar_ax, orientation='vertical')\n",
    "cbar.set_label('ratio of frequencies', fontsize=fontsize)#, labelpad=10)\n",
    "cbar.ax.tick_params(labelsize=fontsize)\n",
    "cbar.set_ticks([0,1,2,3,4,5])\n",
    "\n",
    "fig.savefig('time_latitude_plot_1yr_window.pdf', transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply 30 year smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = [1,6,10,30]\n",
    "count_ratio_2d_cali_smoothed_list = []\n",
    "\n",
    "for w in range(len(windows)):\n",
    "    window=windows[w]\n",
    "    count_ratio_2d_cali_smoothed = numpy.zeros((count_ratio_2d_cali.shape))\n",
    "    for row_idx in range(count_ratio_2d_cali_smoothed.shape[0]):\n",
    "        count_ratio_2d_cali_smoothed[row_idx,:] = pandas.Series(count_ratio_2d_cali[row_idx,:]).rolling(window=window, center=True).mean()\n",
    "    count_ratio_2d_cali_smoothed_list.append(count_ratio_2d_cali_smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize=12\n",
    "for value in range(len(windows)):\n",
    "    \n",
    "    count_ratio_2d_cali_smoothed = count_ratio_2d_cali_smoothed_list[value]\n",
    "\n",
    "    fig = mp.figure(figsize=(8,3))\n",
    "\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    contour_levels = numpy.arange(0,5.1,0.2)\n",
    "\n",
    "    ax_cf = ax.contourf(half_years_hist_rcp, \\\n",
    "                        PRECT_lat[numpy.unique(cali_coast_latlon_indices[:,0])], \\\n",
    "                        count_ratio_2d_cali_smoothed, \\\n",
    "                        norm=MidpointNormalize(midpoint=1.0), \\\n",
    "                        cmap='RdBu', \\\n",
    "                        levels=contour_levels, \\\n",
    "                        extend='max')\n",
    "\n",
    "    ax_sig = ax.contourf(year_middle_list, \\\n",
    "                        PRECT_lat[numpy.unique(cali_coast_latlon_indices[:,0])], \\\n",
    "                        sig_vals_list[value], \\\n",
    "                        #count_ratio_2d_cali_bool, \\\n",
    "                        colors='None', \\\n",
    "                        levels=[0.0,0.01,1.0], \\\n",
    "                        #levels=[0.05,1.5], \\\n",
    "                        hatches=['///',None], \\\n",
    "                        extend='lower', \\\n",
    "                        edgecolors='red', \\\n",
    "                        zorder=2)\n",
    "\n",
    "#     ax_c = ax.contour(half_years_hist_rcp, \\\n",
    "#                         PRECT_lat[numpy.unique(cali_coast_latlon_indices[:,0])], \\\n",
    "#                         count_ratio_2d_cali_smoothed, \\\n",
    "#                         norm=MidpointNormalize(midpoint=1.0), \\\n",
    "#                         levels=[0,0.5,1,1.5,2,3,4,5], \\\n",
    "#                         colors='0.5', \\\n",
    "#                         linestyles=['--']*2+[':']+['-']*5, \\\n",
    "#                         linewidths=[1]*2+[2]+[1]*5, \\\n",
    "#                         zorder=3)\n",
    "\n",
    "#     new_levels = []\n",
    "#     for i in ax_c.levels:\n",
    "#         if i in [0.5,1.5]:\n",
    "#             new_levels.append('{:.1f}'.format(i))\n",
    "#         else:\n",
    "#             new_levels.append('{:.0f}'.format(i))\n",
    "#     ax_c.levels = new_levels\n",
    "#     mp.clabel(ax_c, fontsize=fontsize, colors='0.25')\n",
    "\n",
    "    la_color = 'saddlebrown'\n",
    "    sf_color = 'darkgreen'\n",
    "    od_color = '#007070' # '#008080' is teal\n",
    "\n",
    "    #ax.axhline(LA_lat, c='firebrick', zorder=1)\n",
    "    ax.axhline(LA_lat, c=la_color, zorder=2)\n",
    "    ax.axhline(SF_lat, c=sf_color, zorder=2)\n",
    "    ax.axhline(Oroville_dam_lat, c=od_color, zorder=2)\n",
    "\n",
    "    ax.text(s='LA', x=2105, y=LA_lat, color=la_color, ha='center', va='center', fontsize=fontsize, weight='bold')\n",
    "    ax.text(s='SF', x=2105, y=SF_lat, color=sf_color, ha='center', va='center', fontsize=fontsize, weight='bold')\n",
    "    ax.text(s='OD', x=2105, y=Oroville_dam_lat, color=od_color, ha='center', va='center', fontsize=fontsize, weight='bold')\n",
    "\n",
    "    ax.set_xlim(1920,2100)\n",
    "    ax.set_xticks(numpy.arange(1920,2101,30))\n",
    "    ax.set_yticks(numpy.arange(34,43,2))\n",
    "\n",
    "    ax.text(s='Ratios with smoothing='+sig_vals_labels[value], x=0, y=1.03, transform=ax.transAxes, fontsize=fontsize, ha='left', va='bottom')\n",
    "    ax.tick_params(labelsize=fontsize)\n",
    "\n",
    "    ax.set_ylabel('latitude ('+degree_sign+'N)', fontsize=fontsize)\n",
    "    ax.set_xlabel('year', fontsize=fontsize)\n",
    "\n",
    "    divider = mpl_toolkits.axes_grid1.make_axes_locatable(ax)\n",
    "    cbar_ax = divider.append_axes('right', size='2.5%', pad=0.4)\n",
    "    cbar = fig.colorbar(ax_cf, cax=cbar_ax, orientation='vertical')\n",
    "    cbar.set_label('ratio of frequencies', fontsize=fontsize)#, labelpad=10)\n",
    "    cbar.ax.tick_params(labelsize=fontsize)\n",
    "    cbar.set_ticks([0,1,2,3,4,5])\n",
    "\n",
    "    fig.savefig('time_latitude_plot_'+sig_vals_labels[value]+'_window.pdf', transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRECT_lat_subset = PRECT_lat[numpy.unique(cali_coast_latlon_indices[:,0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert times\n",
    "time_datetime = [datetime.datetime(i,1,15) for i in year_middle_list]\n",
    "time_nc = netCDF4.date2num(time_datetime, units='days since 1920-01-01', calendar='standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save hist clim\n",
    "filename = 'time_latitude_25year_wet_events_PIC_no_smoothing.nc'\n",
    "\n",
    "ncfile = netCDF4.Dataset(filename, 'w', format='NETCDF4')\n",
    "\n",
    "lat_dim = ncfile.createDimension('lat', PRECT_lat_subset.size)\n",
    "time_dim = ncfile.createDimension('time', len(year_middle_list))\n",
    "\n",
    "lat_var = ncfile.createVariable('lat', 'f4', ('lat',))\n",
    "time_var = ncfile.createVariable('time', 'f4', ('time',))\n",
    "lat_var[:] = PRECT_lat_subset\n",
    "time_var[:] = time_nc\n",
    "lat_var.units = 'degrees_north'\n",
    "time_var.units = 'days since 1920-01-01'\n",
    "time_var.description = 'Reported for yearly (seasonal) values; no smoothing or averaging'\n",
    "\n",
    "ratios_of_frequencies = ncfile.createVariable('time_lat_ratios', 'f4', ('lat','time'))\n",
    "ratios_of_frequencies[:] = count_ratio_2d_cali\n",
    "ratios_of_frequencies.units = 'unitless'\n",
    "ratios_of_frequencies.description = 'Ratio of frequencies for coastal California grid points (average of 3 longitudinal values at each California coastal latitude)'\n",
    "\n",
    "counts_hist_rcp = ncfile.createVariable('hist_rcp_counts', 'f4', ('lat','time'))\n",
    "counts_hist_rcp[:] = hist_rcp_counts_2d_cali_coast\n",
    "counts_hist_rcp.units = 'number of exceedances'\n",
    "counts_hist_rcp.description = 'Number of exceedances of PIC event (average of 3 longitudinal values at each California coastal latitude)'\n",
    "\n",
    "counts_pic = ncfile.createVariable('pic_counts', 'f4', ('lat'))\n",
    "counts_pic[:] = pic_counts_2d_cali_coast\n",
    "counts_pic.units = 'number of exceedances'\n",
    "counts_pic.description = 'Number of events in PIC time series (constant value corresponding to appropriate percentile)'\n",
    "\n",
    "return_period_vals_hist_rcp = ncfile.createVariable('return_period_vals_hist_rcp', 'f4', ('lat','time'))\n",
    "return_period_vals_hist_rcp[:] = return_period_values_hist_rcp_cali_coast[:,:,0]\n",
    "return_period_vals_hist_rcp.units = 'mm'\n",
    "return_period_vals_hist_rcp.description = 'Return period precipitation values for hist+RCP8.5 time series (average of 3 longitudinal grid points at each California coastal latitude)'\n",
    "\n",
    "return_period_vals_pic = ncfile.createVariable('return_period_vals_pic', 'f4', ('lat',))\n",
    "return_period_vals_pic[:] = return_period_values_pic_cali_coast[:]\n",
    "return_period_vals_pic.units = 'mm'\n",
    "return_period_vals_pic.description = 'Return period precipitation values for PIC time series (average of 3 longitudinal grid points at each California coastal latitude)'\n",
    "\n",
    "# sig_vals_labels = ['1yr','5yr','10yr','30yr']\n",
    "ad_pvals_1yr = ncfile.createVariable('ad_pvals_1yr', 'f4', ('lat','time'))\n",
    "ad_pvals_1yr[:] = sig_vals_list[0]\n",
    "ad_pvals_1yr.description = 'P-values calculated from the Anderson-Darling k-samples.  Points where this field is < 0.05 are significant at the 95% conf. level; points where < 0.01 are significant at the 99% conf. level, etc.'\n",
    "\n",
    "# sig_vals_labels = ['1yr','5yr','10yr','30yr']\n",
    "ad_pvals_5yr = ncfile.createVariable('ad_pvals_5yr', 'f4', ('lat','time'))\n",
    "ad_pvals_5yr[:] = sig_vals_list[1]\n",
    "ad_pvals_5yr.description = 'P-values calculated from the Anderson-Darling k-samples.  Points where this field is < 0.05 are significant at the 95% conf. level; points where < 0.01 are significant at the 99% conf. level, etc.'\n",
    "\n",
    "# sig_vals_labels = ['1yr','5yr','10yr','30yr']\n",
    "ad_pvals_10yr = ncfile.createVariable('ad_pvals_10yr', 'f4', ('lat','time'))\n",
    "ad_pvals_10yr[:] = sig_vals_list[2]\n",
    "ad_pvals_10yr.description = 'P-values calculated from the Anderson-Darling k-samples.  Points where this field is < 0.05 are significant at the 95% conf. level; points where < 0.01 are significant at the 99% conf. level, etc.'\n",
    "\n",
    "# sig_vals_labels = ['1yr','5yr','10yr','30yr']\n",
    "ad_pvals_30yr = ncfile.createVariable('ad_pvals_30yr', 'f4', ('lat','time'))\n",
    "ad_pvals_30yr[:] = sig_vals_list[3]\n",
    "ad_pvals_30yr.description = 'P-values calculated from the Anderson-Darling k-samples.  Points where this field is < 0.05 are significant at the 95% conf. level; points where < 0.01 are significant at the 99% conf. level, etc.'\n",
    "\n",
    "ncfile.history = 'Created ' + time.ctime(time.time())\n",
    "ncfile.close()\n",
    "print(filename, \"saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
